
---

### Conceptual Code Snippets for Edge AI Drone (Jetson Nano)

#### 1. `drone_ai_module.py` - Core AI and Sensor Processing

```python
import cv2
import torch
import numpy as np
import time
import json
import paho.mqtt.client as mqtt
import logging

# --- Configure Logging ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- MQTT Configuration ---
MQTT_BROKER = "your_mqtt_broker_address" # e.g., "broker.hivemq.com" or your local broker IP
MQTT_PORT = 1883
MQTT_TOPIC_DATA = "disaster_response/drone/data"
MQTT_TOPIC_STATUS = "disaster_response/drone/status"
DRONE_ID = "DRONE_ALPHA_001" # Unique ID for this drone

# --- AI Model Setup (YOLOv5) ---
# Assuming you have YOLOv5 trained weights (e.g., best.pt) and a custom dataset
# Download YOLOv5: git clone https://github.com/ultralytics/yolov5
# Model path on Jetson Nano
YOLO_MODEL_PATH = "yolov5/runs/train/exp/weights/best.pt" # Replace with your actual path
CONFIDENCE_THRESHOLD = 0.5
IOU_THRESHOLD = 0.45

try:
    # Load YOLOv5 model
    # For Jetson, ensure you use 'cuda' if available, otherwise 'cpu'
    model = torch.hub.load('ultralytics/yolov5', 'custom', path=YOLO_MODEL_PATH, force_reload=True)
    model.conf = CONFIDENCE_THRESHOLD # Object confidence threshold
    model.iou = IOU_THRESHOLD      # IoU threshold for NMS
    model.classes = [0, 1, 2] # Example: 0 for 'survivor', 1 for 'fire', 2 for 'flood_area'
                             # Adjust based on your actual trained classes
    logging.info("YOLOv5 model loaded successfully.")
except Exception as e:
    logging.error(f"Error loading YOLOv5 model: {e}")
    exit()

# --- Sensor Simulation (Replace with actual sensor readings) ---
def get_lidar_data_simulated():
    # In a real scenario, this would read from Lidar sensor
    # For simulation, return dummy obstacle detection or mapping data
    return {"obstacle_detected": False, "distance_to_nearest": 0.0, "map_update": [0,0,0]}

def get_gps_data_simulated():
    # In a real scenario, this would read from GPS module
    # For simulation, return dummy coordinates
    return {"latitude": 17.6868 + np.random.uniform(-0.01, 0.01),
            "longitude": 83.2185 + np.random.uniform(-0.01, 0.01),
            "altitude": 100 + np.random.uniform(-5, 5)} # Example for Visakhapatnam

def get_thermal_data_simulated():
    # In a real scenario, this would read from thermal camera
    # For simulation, return a dummy temperature reading or heat signature presence
    return {"heat_signature_present": np.random.rand() > 0.8, "max_temp": np.random.uniform(30, 80)} # Simulate survivor/fire

# --- MQTT Client Setup ---
mqtt_client = mqtt.Client(client_id=DRONE_ID)

def on_connect(client, userdata, flags, rc):
    if rc == 0:
        logging.info("Connected to MQTT Broker!")
        client.publish(MQTT_TOPIC_STATUS, f"{DRONE_ID} connected.", qos=1, retain=True)
    else:
        logging.error(f"Failed to connect, return code {rc}")

mqtt_client.on_connect = on_connect
mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)
mqtt_client.loop_start() # Start a non-blocking loop for MQTT

# --- Main Drone AI Loop ---
def run_drone_ai():
    # For Raspberry Pi Camera, use cv2.VideoCapture(0) or specific GStreamer pipeline
    # For better performance on Jetson, a GStreamer pipeline is recommended.
    # Example GStreamer pipeline (adjust resolution and framerate as needed):
    # GST_STR = 'nvarguscamera ! video/x-raw(memory:NVMM), width=1920, height=1080, format=(string)NV12, framerate=(fraction)30/1 ! nvvidconv flip-method=0 ! video/x-raw, width=640, height=480, format=(string)BGRx ! videoconvert ! video/x-raw, format=(string)BGR ! appsink'
    # cap = cv2.VideoCapture(GST_STR, cv2.CAP_GSTREAMER)
    cap = cv2.VideoCapture(0) # Standard webcam or /dev/video0 if using USB cam

    if not cap.isOpened():
        logging.error("Failed to open camera.")
        return

    logging.info("Starting AI inference loop...")
    frame_count = 0
    start_time = time.time()

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                logging.warning("Failed to grab frame. Exiting.")
                break

            frame_count += 1
            current_time = time.time()
            fps = frame_count / (current_time - start_time)

            # 1. AI Inference (Object Detection)
            results = model(frame) # Perform inference
            detections = results.pandas().xyxy[0].to_dict(orient="records")

            detected_objects = []
            for det in detections:
                label = model.names[int(det['class'])]
                confidence = det['confidence']
                x1, y1, x2, y2 = int(det['xmin']), int(det['ymin']), int(det['xmax']), int(det['ymax'])
                detected_objects.append({
                    "label": label,
                    "confidence": round(confidence, 2),
                    "bbox": [x1, y1, x2, y2]
                })
                # Draw bounding boxes (optional, for debugging/display)
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, f"{label} {confidence:.2f}", (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

            # 2. Integrate other sensor data
            lidar_data = get_lidar_data_simulated()
            gps_data = get_gps_data_simulated()
            thermal_data = get_thermal_data_simulated()

            # 3. Construct payload for MQTT
            payload = {
                "drone_id": DRONE_ID,
                "timestamp": time.time(),
                "gps": gps_data,
                "detections": detected_objects,
                "lidar_info": lidar_data,
                "thermal_info": thermal_data,
                "fps": round(fps, 2)
            }

            # 4. Publish data via MQTT
            try:
                mqtt_client.publish(MQTT_TOPIC_DATA, json.dumps(payload), qos=0)
                logging.debug(f"Published data: {json.dumps(payload)}")
            except Exception as e:
                logging.error(f"Error publishing MQTT message: {e}")

            # Optional: Display frame (can be disabled for headless operation)
            # cv2.imshow('Drone Feed', frame)
            # if cv2.waitKey(1) & 0xFF == ord('q'):
            #     break

            time.sleep(0.1) # Simulate processing delay, adjust as needed

    except KeyboardInterrupt:
        logging.info("Stopping drone AI module.")
    finally:
        cap.release()
        cv2.destroyAllWindows()
        mqtt_client.loop_stop()
        mqtt_client.disconnect()
        logging.info("Disconnected from MQTT Broker.")

if __name__ == "__main__":
    run_drone_ai()
```

#### 2. `firebase_listener.py` - Python Script for Ground Station/Backend (receives MQTT, sends to Firebase)

This script would typically run on a more powerful machine or a cloud instance, acting as a bridge between MQTT and Firebase.

```python
import paho.mqtt.client as mqtt
import firebase_admin
from firebase_admin import credentials
from firebase_admin import firestore
from firebase_admin import db # If using Realtime Database

import json
import logging
import time

# --- Configure Logging ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Firebase Setup ---
# Initialize Firebase Admin SDK
# Make sure your 'serviceAccountKey.json' is secure and not publicly exposed
# Download this file from your Firebase Project Settings -> Service Accounts -> Generate new private key
try:
    cred = credentials.Certificate("path/to/your/serviceAccountKey.json") # IMPORTANT: Replace with actual path
    firebase_admin.initialize_app(cred, {
        'databaseURL': 'https://your-project-id.firebaseio.com' # If using Realtime Database
    })
    firestore_db = firestore.client()
    logging.info("Firebase initialized successfully.")
except Exception as e:
    logging.error(f"Error initializing Firebase: {e}")
    exit()

# --- MQTT Configuration (Same as drone) ---
MQTT_BROKER = "your_mqtt_broker_address"
MQTT_PORT = 1883
MQTT_TOPIC_DATA = "disaster_response/drone/data"
MQTT_TOPIC_STATUS = "disaster_response/drone/status"

# --- MQTT Callbacks ---
def on_connect(client, userdata, flags, rc):
    if rc == 0:
        logging.info("Connected to MQTT Broker!")
        client.subscribe(MQTT_TOPIC_DATA)
        client.subscribe(MQTT_TOPIC_STATUS)
        logging.info(f"Subscribed to topics: {MQTT_TOPIC_DATA}, {MQTT_TOPIC_STATUS}")
    else:
        logging.error(f"Failed to connect, return code {rc}")

def on_message(client, userdata, msg):
    try:
        topic = msg.topic
        payload = msg.payload.decode('utf-8')
        data = json.loads(payload)
        logging.info(f"Received message on topic '{topic}': {data}")

        if topic == MQTT_TOPIC_DATA:
            drone_id = data.get("drone_id", "unknown_drone")
            timestamp = data.get("timestamp", time.time())
            
            # Add/Update data in Firestore
            doc_ref = firestore_db.collection('drones').document(drone_id).collection('missions').document(str(int(timestamp)))
            doc_ref.set(data) # Store the entire payload
            
            # You might also want a 'current_status' document for each drone
            firestore_db.collection('drones').document(drone_id).set({
                'last_update': timestamp,
                'last_gps': data.get('gps'),
                'current_detections': data.get('detections')
            }, merge=True) # merge=True to update fields without overwriting the whole document
            
            logging.info(f"Data for {drone_id} sent to Firestore.")

        elif topic == MQTT_TOPIC_STATUS:
            drone_id_status = data.split(' ')[0] # Assuming "DRONE_ID connected." format
            firestore_db.collection('drones').document(drone_id_status).update({
                'status': data,
                'last_status_update': time.time()
            })
            logging.info(f"Status for {drone_id_status} sent to Firestore.")

    except json.JSONDecodeError:
        logging.error(f"Failed to decode JSON from message: {msg.payload}")
    except Exception as e:
        logging.error(f"Error processing MQTT message: {e}")

# --- Main MQTT Listener Setup ---
mqtt_client = mqtt.Client("FirebaseListener")
mqtt_client.on_connect = on_connect
mqtt_client.on_message = on_message

try:
    mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)
    mqtt_client.loop_forever() # Keep listening for messages
except Exception as e:
    logging.error(f"Could not connect to MQTT Broker: {e}")
```

#### 3. **`dashboard_frontend` (Conceptual)**

This would be a web application (e.g., React, Angular, Vue, or plain HTML/JS) that uses the Firebase SDK to listen for updates in your Firestore database and display them in real-time on a map, with detection overlays, and status indicators.

**Example `index.html` (simplified, using Firebase JS SDK)**

```html
<!DOCTYPE html>
<html>
<head>
    <title>Disaster Response Drone Dashboard</title>
    <script src="https://www.gstatic.com/firebasejs/9.6.0/firebase-app-compat.js"></script>
    <script src="https://www.gstatic.com/firebasejs/9.6.0/firebase-firestore-compat.js"></script>
    <script src="https://www.gstatic.com/firebasejs/9.6.0/firebase-database-compat.js"></script>
    <style>
        #map { height: 600px; width: 100%; }
        #drone-status { margin-top: 20px; }
    </style>
</head>
<body>
    <h1>AIoT Disaster Response Dashboard</h1>
    <div id="map"></div>
    <div id="drone-status">
        <h2>Drone Status:</h2>
        <ul id="status-list"></ul>
    </div>

    <script>
        // Your web app's Firebase configuration
        const firebaseConfig = {
            apiKey: "YOUR_API_KEY",
            authDomain: "YOUR_PROJECT_ID.firebaseapp.com",
            projectId: "YOUR_PROJECT_ID",
            storageBucket: "YOUR_PROJECT_ID.appspot.com",
            messagingSenderId: "YOUR_MESSAGING_SENDER_ID",
            appId: "YOUR_APP_ID",
            databaseURL: "https://YOUR_PROJECT_ID.firebaseio.com" // If using Realtime Database
        };

        // Initialize Firebase
        firebase.initializeApp(firebaseConfig);
        const db = firebase.firestore();
        // const rtdb = firebase.database(); // If using Realtime Database

        const mapDiv = document.getElementById('map');
        const statusList = document.getElementById('status-list');

        // --- Initialize Map (Conceptual, requires actual map library setup) ---
        let map; // global map object
        let droneMarkers = {}; // To store map markers for each drone

        function initMap() {
            // Replace with actual map library initialization (e.g., Google Maps API, Leaflet.js with OpenStreetMap)
            // Example for Leaflet:
            // map = L.map('map').setView([17.6868, 83.2185], 13); // Centered on Visakhapatnam
            // L.tileLayer('https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {
            //     attribution: '&copy; <a href="https://www.openstreetmap.org/copyright">OpenStreetMap</a> contributors'
            // }).addTo(map);
            console.log("Map initialized (placeholder)");
        }
        initMap(); // Call map initialization

        // --- Firestore Listener ---
        db.collection('drones').onSnapshot((snapshot) => {
            snapshot.docChanges().forEach((change) => {
                const droneData = change.doc.data();
                const droneId = change.doc.id;
                const gps = droneData.last_gps;
                const detections = droneData.current_detections;
                const status = droneData.status || "Unknown";

                let statusHtml = `<li><strong>${droneId}</strong>: ${status} (Last Update: ${new Date(droneData.last_update * 1000).toLocaleString()})`;
                if (gps) {
                    statusHtml += `<br>Location: Lat ${gps.latitude.toFixed(4)}, Lon ${gps.longitude.toFixed(4)}`;
                    // Update drone marker on map
                    if (map && typeof L !== 'undefined') { // Check if Leaflet map is initialized
                        if (droneMarkers[droneId]) {
                            droneMarkers[droneId].setLatLng([gps.latitude, gps.longitude]);
                        } else {
                            droneMarkers[droneId] = L.marker([gps.latitude, gps.longitude]).addTo(map)
                                .bindPopup(`<b>${droneId}</b><br>Lat: ${gps.latitude.toFixed(4)}, Lon: ${gps.longitude.toFixed(4)}`);
                        }
                    }
                }
                if (detections && detections.length > 0) {
                    statusHtml += `<br>Detections: `;
                    detections.forEach(det => {
                        statusHtml += `${det.label} (${(det.confidence * 100).toFixed(1)}%) `;
                    });
                }
                statusHtml += `</li>`;

                let existingItem = document.getElementById(`drone-${droneId}`);
                if (existingItem) {
                    existingItem.innerHTML = statusHtml;
                } else {
                    const newItem = document.createElement('li');
                    newItem.id = `drone-${droneId}`;
                    newItem.innerHTML = statusHtml;
                    statusList.appendChild(newItem);
                }
            });
        });

    </script>
</body>
</html>
```

---

